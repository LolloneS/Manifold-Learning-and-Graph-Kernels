{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold Learning and Graph Kernels\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sys\n",
    "import threading\n",
    "from copy import deepcopy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the datasets\n",
    "* Load the datasets\n",
    "* Take the `G` and `labels` fields\n",
    "* `G` consists in a list containing a list of arrays. Remove the external list. Afterwards take only the `am` field\n",
    "* `labels` consists in many one-element lists. Create a single list removing one depth level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URI = '/home/lorenzo/Dropbox/manifold-learning-and-graph-kernels/dataset/'\n",
    "SHOCK_URI = 'SHOCK.mat'\n",
    "PPI_URI = 'PPI.mat'\n",
    "# `G` and `labels`\n",
    "SHOCK = sio.loadmat(BASE_URI + SHOCK_URI)\n",
    "SHOCK_G = SHOCK['G'][0] # read and get rid of external list\n",
    "SHOCK_G_adj = SHOCK_G['am'] # take only the adjacency matrix\n",
    "SHOCK_labels = SHOCK['labels'].reshape(-1) # read and get rid of useless 1-element lists\n",
    "assert len(SHOCK_G_adj) == len(SHOCK_labels)\n",
    "del SHOCK\n",
    "PPI = sio.loadmat(BASE_URI + PPI_URI)\n",
    "PPI_G = PPI['G'][0]\n",
    "PPI_G_adj = PPI_G['am']\n",
    "PPI_labels = PPI['labels'].reshape(-1)\n",
    "assert len(PPI_G_adj) == len(PPI_labels)\n",
    "del PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(SHOCK_G.dtype.names) # [('am', 'O'), ('nl', 'O'), ('al', 'O')]\n",
    "# print(SHOCK_G)\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# x = PPI_G_adj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0, 1, 1, ..., 0, 0, 1],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "# x = [PPI_G_adj[0]]\n",
    "# print(PPI_G_adj.shape[0])\n",
    "# print(len(PPI_G_adj))\n",
    "# print(np.ones((PPI_G_adj.shape[0],1)))\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weisfeiler-Lehman\n",
    "### Algorithm\n",
    "\n",
    "1. Multiset label determination\n",
    "    * assign a multiset label $M_i(v)$ to each node $v \\in G$ which consists of the multiset $\\{l_{i-1}(u)$ | u is a neighbor of v$\\}$\n",
    "        * done in `determine_labels`\n",
    "        * as per the paper, since our graphs are unlabelled, we use the node-degrees as starting labels for the node\n",
    "\n",
    "\n",
    "2. Sorting each multiset\n",
    "    * Sort elements in $M_i(v)$ in ascending order and concatenate them into a string $s_i(v)$\n",
    "        * sorted and merged in `get_labels` \n",
    "    * Add $l_{i−1}(v)$ as a prefix to $s_i(v)$\n",
    "        * done in `get_string_from_multiset`. Returns the string formatted as requested\n",
    "\n",
    "\n",
    "3. Label compression\n",
    "    * Map each string $s_i(v)$ to a compressed label using a hash function $f : \\Sigma^∗ \\rightarrow \\Sigma$ such that $f(s_i(v)) = f(s_i (w))$ if and only if $s_i(v) = s_i(w)$\n",
    "        * done in `compress_label` and `relabel`\n",
    "    * As the first \"hash\", I use the highest degree of a node in all graphs, plus one (hence I'm sure that one is a hash instead of an original label\n",
    "\n",
    "\n",
    "4. Relabeling\n",
    "    * Set $l_i(v) = f(s_i(v))$ for all nodes in $G$ \n",
    "        * done in `relabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeisfeilerLehman:\n",
    "    '''\n",
    "    Get a graph's starting labels (node degrees).\n",
    "    graph --> actual graph\n",
    "    '''\n",
    "    def get_graph_starting_labels(self, graph):\n",
    "        return np.dot(graph, np.ones((len(graph), 1)))\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Get the starting labels for all the graphs (node degrees)\n",
    "    {index of the graph in the graphs list : array representing starting label}\n",
    "    '''\n",
    "    def get_all_starting_labels(self):\n",
    "        return {g : self.get_graph_starting_labels(self.graphs[g]) for g in range(len(self.graphs))}\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Get the highest degree of a node throughout all graphs\n",
    "    '''\n",
    "    def get_max_global_degree(self):\n",
    "        return max([max(v) for _, v in self.get_all_starting_labels().items()])\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Get the neighbors of a node\n",
    "    g --> index of the graph\n",
    "    node --> index of the node\n",
    "    '''\n",
    "    def get_neighbors(self, g, node):\n",
    "        graph = self.graphs[g]\n",
    "        neighbors = [j for j in range(len(graph)) if graph[node][j] == 1]\n",
    "        return neighbors\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Get updated labels for a node as per (1)\n",
    "    g --> index of the graph\n",
    "    node --> index of the node in the graph\n",
    "    '''\n",
    "    def get_labels(self, g, node):\n",
    "        new_label = sorted([self.labels[g][i] for i in self.get_neighbors(g, node)])\n",
    "        new_label = ''.join(str(int(i)) for i in new_label)\n",
    "        return new_label\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Return the new multiset of labels of each node in a graph\n",
    "    g --> index of the graph in the graphs array\n",
    "    '''\n",
    "    def determine_labels(self, g):\n",
    "        new_labels = {k : self.get_labels(g, k) for k in range(len(self.graphs[g]))}\n",
    "        return new_labels\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Return the string obtained from the sorted multiset \n",
    "    g --> index of the graph in the array\n",
    "    '''\n",
    "    def get_string_from_multiset(self, g, new_labels):\n",
    "        for k in new_labels: # new_labels is a dict\n",
    "            new_labels[k] = self.labels[g][k] + new_labels[k]\n",
    "        return new_labels    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Compress a label if it has not been compressed already\n",
    "    '''\n",
    "    def compress_label(self, label):\n",
    "        if label not in self.compressed_labels:\n",
    "            self.compressed_labels[label] = str(self.compressed_index)\n",
    "            self.compressed_index += 1\n",
    "        return self.compressed_labels[label]\n",
    "    '''\n",
    "      A\n",
    "     / \\\n",
    "    X-B-Y    come differenzio X e Y? me ne frego...\n",
    "     \\ /\n",
    "      C\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Relabel all the nodes in a graph\n",
    "    '''\n",
    "    def relabel(self, g, new_labels):\n",
    "        assert len(new_labels) == len(self.labels[g])\n",
    "        for i in range(len(new_labels)):\n",
    "            self.labels[g][i] = self.compress_label(new_labels[i])\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    From graph to feature vector representation\n",
    "    g --> index of the graph\n",
    "    '''\n",
    "    def graph_to_feature_vector(self, g):\n",
    "        phi = []\n",
    "        ol = list(map(int, self.original_labels[g]))\n",
    "        c = Counter(ol)\n",
    "        for k in range(max(ol)):\n",
    "            if k in c:\n",
    "                phi.append(c[k])\n",
    "            else:\n",
    "                phi.append(0)\n",
    "        return phi\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Pairwise similarities between all the graphs (unnormalized)\n",
    "    '''\n",
    "    def pairwise_similarities(self):\n",
    "        ps = {}\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                print(np.dot(self.graph_to_feature_vector(i), self.graph_to_feature_vector(j)))\n",
    "        print(ps)\n",
    "        return ps\n",
    "    \n",
    "    '''\n",
    "    Run the whole algorithm: steps 1, 2, 3, 4\n",
    "    '''\n",
    "    def run(self):\n",
    "        for i in range(self.h):\n",
    "            for g in range(len(self.graphs)): # g is the index of the graph in the array of graphs\n",
    "                new_labels = self.determine_labels(g)\n",
    "                new_labels = self.get_string_from_multiset(g, new_labels)\n",
    "                self.relabel(g, new_labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Initialize everything and run the algorithm h times\n",
    "    '''\n",
    "    def __init__(self, graphs, h):\n",
    "        self.n = len(graphs)\n",
    "        self.graphs = graphs\n",
    "        self.h = h\n",
    "        self.labels = self.get_all_starting_labels()\n",
    "        self.labels = { \n",
    "                        index : [str(int(degree)) for degree in self.labels[index].ravel()] \n",
    "                                                  for index in self.labels \n",
    "                      }\n",
    "        self.original_labels = deepcopy(self.labels)\n",
    "        # print(self.original_labels[0])\n",
    "        self.compressed_index = int(self.get_max_global_degree()[0]) \n",
    "        self.compressed_labels = {}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (66,) and (24,) not aligned: 66 (dim 0) != 24 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-284782f04b8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# print(wl_SHOCK.labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mwl_PPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-6e1b60fcd9d3>\u001b[0m in \u001b[0;36mpairwise_similarities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_to_feature_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_to_feature_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (66,) and (24,) not aligned: 66 (dim 0) != 24 (dim 0)"
     ]
    }
   ],
   "source": [
    "wl_PPI = WeisfeilerLehman(PPI_G_adj, 4)\n",
    "t1 = threading.Thread(name=\"PPI\", target=wl_PPI.run)\n",
    "wl_SHOCK = WeisfeilerLehman(SHOCK_G_adj, 4)\n",
    "t2 = threading.Thread(name=\"SHOCK\", target=wl_SHOCK.run)\n",
    "threads = [t1, t2]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "# print(wl_PPI.labels)\n",
    "# print(wl_SHOCK.labels)\n",
    "\n",
    "wl_PPI.pairwise_similarities()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
