{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold Learning and Graph Kernels\n",
    "### Requirements \n",
    "Read [this article](http://www.dsi.unive.it/~atorsell/AI/graph/Unfolding.pdf) presenting a way to improve the disciminative power of graph kernels.\n",
    "Choose one [graph kernel](http://www.dsi.unive.it/~atorsell/AI/graph/kernels.pdf) among\n",
    "\n",
    "* Shortest-path Kernel\n",
    "* Graphlet Kernel\n",
    "* Random Walk Kernel\n",
    "* Weisfeiler-Lehman Kernel\n",
    "\n",
    "\n",
    "Choose one manifold learning technique among\n",
    "\n",
    "* Isomap\n",
    "* Diffusion Maps\n",
    "* Laplacian Eigenmaps\n",
    "* Local Linear Embedding\n",
    "\n",
    "\n",
    "Compare the performance of an SVM trained on the given kernel, with or without the manifold learning step, on the following datasets:\n",
    "\n",
    "* [PPI](http://www.dsi.unive.it/~atorsell/AI/graph/PPI.mat): this is a Protein-Protein Interaction dataset. Here proteins (nodes) are connected by an edge in the graph if they have a physical or functional association.\n",
    "* [Shock](http://www.dsi.unive.it/~atorsell/AI/graph/Shock.mat): representing 2D shapes. Each graph is a skeletal-based representation of the differential structure of the boundary of a 2D shape.\n",
    "\n",
    "**Note**: the datasets are contained in Matlab files. The variable `G` contains a vector of cells, one per graph. \n",
    "The entry `am` of each cell is the adjacency matrix of the graph.\n",
    "The variable `labels`, contains the class-labels of each graph.\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sys\n",
    "import threading\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from sklearn import svm, manifold, preprocessing\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the datasets\n",
    "* Load the datasets\n",
    "* Take the `G` and `labels` fields\n",
    "* `G` consists in a list containing a list of arrays. Remove the external list. Afterwards take only the `am` field\n",
    "* `labels` consists in many one-element lists. Create a single list removing one depth level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URI = '/home/lorenzo/Dropbox/manifold-learning-and-graph-kernels/dataset/'\n",
    "SHOCK_URI = 'SHOCK.mat'\n",
    "PPI_URI = 'PPI.mat'\n",
    "# `G` and `labels`\n",
    "SHOCK = sio.loadmat(BASE_URI + SHOCK_URI)\n",
    "SHOCK_G = SHOCK['G'][0] # read and get rid of external list\n",
    "# print(SHOCK_G.dtype.names) \n",
    "# [('am', 'O'), ('nl', 'O'), ('al', 'O')]\n",
    "SHOCK_G_adj = SHOCK_G['am'] # take only the adjacency matrix\n",
    "SHOCK_labels = SHOCK['labels'].ravel() # read and get rid of useless 1-element lists\n",
    "assert len(SHOCK_G_adj) == len(SHOCK_labels)\n",
    "del SHOCK\n",
    "PPI = sio.loadmat(BASE_URI + PPI_URI)\n",
    "PPI_G = PPI['G'][0]\n",
    "PPI_G_adj = PPI_G['am']\n",
    "PPI_labels = PPI['labels'].ravel()\n",
    "assert len(PPI_G_adj) == len(PPI_labels)\n",
    "del PPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weisfeiler-Lehman\n",
    "### Algorithm\n",
    "\n",
    "1. Multiset label determination\n",
    "    * assign a multiset label $M_i(v)$ to each node $v \\in G$ which consists of the multiset $\\{l_{i-1}(u)$ | u is a neighbor of v$\\}$\n",
    "        * done in `determine_labels`\n",
    "        * as per the paper, since our graphs are unlabelled, we use the node-degrees as starting labels for the node\n",
    "\n",
    "\n",
    "2. Sorting each multiset\n",
    "    * Sort elements in $M_i(v)$ in ascending order and concatenate them into a string $s_i(v)$\n",
    "        * sorted and merged in `get_labels` \n",
    "    * Add $l_{i−1}(v)$ as a prefix to $s_i(v)$\n",
    "        * done in `extend_labels`. Returns the string formatted as requested\n",
    "\n",
    "\n",
    "3. Label compression\n",
    "    * Map each string $s_i(v)$ to a compressed label using a hash function $f : \\Sigma^∗ \\rightarrow \\Sigma$ such that $f(s_i(v)) = f(s_i (w))$ if and only if $s_i(v) = s_i(w)$\n",
    "        * done in `compress_label` and `relabel`\n",
    "    * As the first \"hash\", I use the highest degree of a node in all graphs, plus one (hence I'm sure that one is a hash instead of an original label\n",
    "\n",
    "\n",
    "4. Relabeling\n",
    "    * Set $l_i(v) = f(s_i(v))$ for all nodes in $G$ \n",
    "        * done in `relabel`\n",
    "\n",
    "\n",
    "After having done all of the above, the similarity matrix for the N graphs is computed.\n",
    "The `run()` method returns the similarity matrix containing the normalized values for all the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeisfeilerLehman:\n",
    "    '''\n",
    "    Get a graph's starting labels (node degrees).\n",
    "    graph --> actual graph\n",
    "    '''\n",
    "    def get_graph_starting_labels(self, graph):\n",
    "        return np.dot(graph, np.ones((len(graph), 1)))\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Get the starting labels for all the graphs (node degrees)\n",
    "    {index of the graph in the graphs list : array representing starting label}\n",
    "    '''\n",
    "    def get_all_starting_labels(self):\n",
    "        starting_labels = {g : self.get_graph_starting_labels(self.graphs[g]) \n",
    "                                                              for g in range(self.n)}\n",
    "        return starting_labels\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Get the highest degree of a node throughout all graphs\n",
    "    '''\n",
    "    def get_max_global_degree(self):\n",
    "        return max([max(v) for _, v in self.get_all_starting_labels().items()])\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Get the neighbors of a node\n",
    "    g --> index of the graph\n",
    "    node --> index of the node\n",
    "    neighbors --> list with indices of the neighbors\n",
    "    '''\n",
    "    def get_neighbors(self, g, node):\n",
    "        graph = self.graphs[g]\n",
    "        neighbors = [j for j in range(len(graph)) if graph[node][j] == 1]\n",
    "        return neighbors\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Get updated labels for a node as per (1)\n",
    "    g --> index of the graph\n",
    "    node --> index of the node in the graph\n",
    "    \n",
    "    Take the labels of the neighbors of a node, sort them, merge them into an unique string\n",
    "    '''\n",
    "    def get_labels(self, g, node):\n",
    "        new_label = sorted([self.labels[g][i] for i in self.get_neighbors(g, node)])\n",
    "        new_label = ''.join(str(int(i)) for i in new_label)\n",
    "        return new_label\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Compute the new multiset of labels of each node in a graph.\n",
    "    Return a dictionary in which the key is the index of the node and the value is the string returned from the \n",
    "            `get_labels` function\n",
    "    g --> index of the graph in the graphs array\n",
    "    '''\n",
    "    def determine_labels(self, g):\n",
    "        new_labels = {k : self.get_labels(g, k) for k in range(len(self.graphs[g]))}\n",
    "        return new_labels\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Return the string obtained from the sorted multiset \n",
    "    g --> index of the graph in the array\n",
    "    '''\n",
    "    def extend_labels(self, g, new_labels):\n",
    "        for k in new_labels: # new_labels is a dict\n",
    "            new_labels[k] = self.labels[g][k] + new_labels[k]\n",
    "        return new_labels    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Compress a label if it has not been compressed already\n",
    "    {long_label : compressed_index}\n",
    "    '''\n",
    "    def compress_label(self, label):\n",
    "        if label not in self.compressed_labels:\n",
    "            self.compressed_labels[label] = str(self.compressed_index)\n",
    "            self.compressed_index += 1\n",
    "        return self.compressed_labels[label]\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Relabel all the nodes in a graph\n",
    "    '''\n",
    "    def relabel(self, g, new_labels):\n",
    "        # print(f'OLD: {self.labels}')\n",
    "        assert len(new_labels) == len(self.labels[g])\n",
    "        for i in range(len(new_labels)):\n",
    "            self.labels[g][i] = self.compress_label(new_labels[i])\n",
    "        # print(f'NEW: {self.labels}')\n",
    "        \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Count the original node labels: return a list with the number of occurrences per each label\n",
    "    g --> index of the graph\n",
    "    [0, 1, 2, 3, 1] --> 0 nodes with label 0, 1 node with label 1, ..., 1 node with label 4\n",
    "    '''\n",
    "    def count_original_node_labels(self, g):\n",
    "        phi = []\n",
    "        ol = list(map(int, self.original_labels[g]))\n",
    "        c = Counter(ol)\n",
    "        for k in range(max(ol)+1):\n",
    "            if k in c:\n",
    "                phi.append(c[k])\n",
    "            else:\n",
    "                phi.append(0)\n",
    "        return phi\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Count node labels at current iteration: return a list with the number of occurrences per each label\n",
    "    g --> index of the graph\n",
    "    '''\n",
    "    def count_node_labels_at_current_iteration(self, g):\n",
    "        phi = []\n",
    "        l = list(map(int, [i for _, i in self.compressed_labels.items()]))\n",
    "        c = Counter(l)\n",
    "        for k in range(max(l)+1):\n",
    "            if k in c:\n",
    "                phi.append(c[k])\n",
    "            else:\n",
    "                phi.append(0)\n",
    "        return phi\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Prepare feature vectors for the dot product. Make the shorter ones as long as the long ones,\n",
    "    concatenate, and so on.\n",
    "    g1, g2 --> indices of two graphs\n",
    "    '''\n",
    "    def prepare_feature_vectors(self, g1, g2):\n",
    "        l1 = self.count_labels[g1]\n",
    "        l2 = self.count_labels[g2]\n",
    "        # print(f'l1:{l1}\\n')\n",
    "        # print(f'l2:{l2}\\n')\n",
    "        tot1 = []\n",
    "        tot2 = []\n",
    "        for i in range(self.h+1):\n",
    "            if len(l1[i]) > len(l2[i]):\n",
    "                a1, a2 = np.array(l1[i]), np.zeros(len(l1[i]))\n",
    "                for j in range(len(l2[i])):\n",
    "                    a2[j] = l2[i][j]\n",
    "                # print(f'a1:{a1}')\n",
    "                # print(f'a2:{a2}')\n",
    "            else:\n",
    "                a1, a2 = np.zeros(len(l2[i])), np.array(l2[i])\n",
    "                for j in range(len(l1[i])):\n",
    "                    a1[j] = l1[i][j]\n",
    "                # print(f'a1:{a1}')\n",
    "                # print(f'a2:{a2}')\n",
    "            tot1 = np.concatenate((tot1, a1), axis=0)\n",
    "            tot2 = np.concatenate((tot2, a2), axis=0)\n",
    "            # print(f'tot1:{tot1}')\n",
    "            # print(f'tot2:{tot2}')\n",
    "        return tot1, tot2\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Normalize similarity matrix: sum per rows must be = 1\n",
    "    '''\n",
    "    def normalize_sim_matrix(self):\n",
    "        self.pairwise_sim_matrix = preprocessing.normalize(self.pairwise_sim_matrix)\n",
    "        return self.pairwise_sim_matrix\n",
    "    \n",
    "    '''\n",
    "    Pairwise similarities between all the graphs (unnormalized)\n",
    "    '''\n",
    "    def pairwise_similarities(self):\n",
    "        for i in range(self.n):\n",
    "            for j in range(i, self.n):\n",
    "                g1, g2 = self.prepare_feature_vectors(i, j)\n",
    "                # print(f'g1\\n{g1}\\n')\n",
    "                # print(f'g2\\n{g2}\\n\\n\\n')\n",
    "                dotp = np.dot(g1, g2)\n",
    "                # print(dotp)\n",
    "                self.pairwise_sim_matrix[i][j] = dotp\n",
    "                self.pairwise_sim_matrix[j][i] = dotp\n",
    "        # print(self.pairwise_sim_matrix)\n",
    "        self.normalize_sim_matrix()\n",
    "        return self.pairwise_sim_matrix\n",
    "    \n",
    "    '''\n",
    "    Run the whole algorithm: steps 1, 2, 3, 4\n",
    "    '''\n",
    "    def run(self):\n",
    "        for i in range(self.h):\n",
    "            for g in range(self.n): # g is the index of the graph in the array of graphs\n",
    "                print(f'old labels of {g} at iteration {i} : {self.labels[g]}')\n",
    "                new_labels = self.determine_labels(g)\n",
    "                new_labels = self.extend_labels(g, new_labels)\n",
    "                self.relabel(g, new_labels)\n",
    "                self.count_labels[g][i+1] = self.count_node_labels_at_current_iteration(g)\n",
    "                print(f'new labels of {g} at iteration {i} : {self.labels[g]}')\n",
    "            # print('\\n\\n')\n",
    "            # print(self.labels)\n",
    "        return self.pairwise_similarities()\n",
    "\n",
    "    '''\n",
    "    Initialize everything and run the algorithm h times\n",
    "    '''\n",
    "    def __init__(self, graphs, h):\n",
    "        self.n = len(graphs)\n",
    "        self.graphs = graphs\n",
    "        self.h = h\n",
    "        self.labels = self.get_all_starting_labels()\n",
    "        self.labels = { \n",
    "                        index : [str(int(degree)) for degree in self.labels[index].ravel()] \n",
    "                                                  for index in self.labels \n",
    "                      }\n",
    "        # print(self.labels)\n",
    "        self.original_labels = deepcopy(self.labels)\n",
    "        # self.compressed_index = 0\n",
    "        self.compressed_index = int(self.get_max_global_degree()[0]) + 1\n",
    "        self.compressed_labels = {}\n",
    "        self.count_labels = {} # {iterazione1 : {grafo1 : conteggio1, grafo2 : conteggio2, ...}, ...}\n",
    "        for i in range(self.n):\n",
    "            self.count_labels[i] = {}\n",
    "            self.count_labels[i][0] = self.count_original_node_labels(i)            \n",
    "        del self.original_labels\n",
    "        # print(self.count_labels)\n",
    "        self.pairwise_sim_matrix = np.zeros((self.n, self.n))\n",
    "        # print(self.labels)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity matrices for PPI and SHOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old labels of 0 at iteration 0 : ['3', '3', '3', '5', '2', '2']\n",
      "new labels of 0 at iteration 0 : ['13', '13', '13', '14', '15', '15']\n",
      "old labels of 1 at iteration 0 : ['3', '3', '3', '5', '2', '2']\n",
      "new labels of 1 at iteration 0 : ['13', '13', '13', '14', '15', '15']\n",
      "old labels of 2 at iteration 0 : ['1', '2', '5', '4', '5', '5', '5', '12', '2', '9', '5', '3', '3', '1', '1', '7', '1', '8', '1', '4', '4', '1', '6', '2', '1', '4', '2', '4', '2', '4', '8', '4', '2', '3', '3', '1', '3', '4', '1', '3', '1', '1', '3', '4', '1', '1', '1', '2']\n",
      "new labels of 2 at iteration 0 : ['16', '17', '18', '19', '18', '18', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '28', '32', '33', '34', '35', '36', '28', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '27', '47', '48', '27', '49', '27', '28', '50', '19', '16', '51', '51', '52']\n",
      "old labels of 0 at iteration 1 : ['13', '13', '13', '14', '15', '15']\n",
      "new labels of 0 at iteration 1 : ['53', '53', '53', '54', '55', '55']\n",
      "old labels of 1 at iteration 1 : ['13', '13', '13', '14', '15', '15']\n",
      "new labels of 1 at iteration 1 : ['53', '53', '53', '54', '55', '55']\n",
      "old labels of 2 at iteration 1 : ['16', '17', '18', '19', '18', '18', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '28', '32', '33', '34', '35', '36', '28', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '27', '47', '48', '27', '49', '27', '28', '50', '19', '16', '51', '51', '52']\n",
      "new labels of 2 at iteration 1 : ['56', '57', '58', '59', '58', '58', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '68', '72', '73', '74', '75', '76', '68', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '87', '90', '91', '68', '92', '59', '93', '94', '95', '96']\n",
      "[[0.49663157 0.49663157 0.71183858]\n",
      " [0.49663157 0.49663157 0.71183858]\n",
      " [0.15758847 0.15758847 0.9748496 ]]\n"
     ]
    }
   ],
   "source": [
    "# x = [PPI_G_adj[i] for i in range(20, 50)]\n",
    "# print(x)\n",
    "\n",
    "x = [PPI_G_adj[44], PPI_G_adj[45], PPI_G_adj[46]]\n",
    "wl_PPI = WeisfeilerLehman(x, 2)\n",
    "\n",
    "# wl_PPI = WeisfeilerLehman(PPI_G_adj,2)\n",
    "# print(wl_PPI.run())\n",
    "\n",
    "\n",
    "# wl_PPI = WeisfeilerLehman(PPI_G_adj,2)\n",
    "wl_PPI.run()\n",
    "\n",
    "# wl_SHOCK = WeisfeilerLehman(SHOCK_G_adj, 3)\n",
    "# t1 = threading.Thread(name=\"PPI\", target=wl_PPI.run)\n",
    "# t2 = threading.Thread(name=\"SHOCK\", target=wl_SHOCK.run)\n",
    "# threads = [t1, t2]\n",
    "# for t in threads:\n",
    "#     t.start()\n",
    "# for t in threads:\n",
    "#     t.join()\n",
    "\n",
    "# SHOCK_sm = wl_SHOCK.pairwise_sim_matrix\n",
    "\n",
    "PPI_sm = wl_PPI.pairwise_sim_matrix\n",
    "print(PPI_sm)\n",
    "# print([PPI_G_adj[i] for i in range(40,50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 5.15864429e-02 3.88837049e-02\n",
      "  5.17022054e-02 5.33979990e-02 2.78301211e-01 3.51710646e-01\n",
      "  3.30270081e-01 5.77252236e-02 5.77252236e-02 6.36135430e-02\n",
      "  3.49873635e-01 3.25137047e-01 1.06993303e-01 3.66835551e-01\n",
      "  1.63525592e-01 1.53420569e-01 1.44028342e-01 1.82684982e-01\n",
      "  2.65005776e-01 2.21213755e-01 4.50767453e-01 3.07780632e-01\n",
      "  4.98166068e-01 4.98166068e-01 3.82586229e-01 4.57076320e-01\n",
      "  4.91967638e-01 3.45105456e-01]\n",
      " [0.00000000e+00 0.00000000e+00 5.15864429e-02 3.88837049e-02\n",
      "  5.17022054e-02 5.33979990e-02 2.78301211e-01 3.51710646e-01\n",
      "  3.30270081e-01 5.77252236e-02 5.77252236e-02 6.36135430e-02\n",
      "  3.49873635e-01 3.25137047e-01 1.06993303e-01 3.66835551e-01\n",
      "  1.63525592e-01 1.53420569e-01 1.44028342e-01 1.82684982e-01\n",
      "  2.65005776e-01 2.21213755e-01 4.50767453e-01 3.07780632e-01\n",
      "  4.98166068e-01 4.98166068e-01 3.82586229e-01 4.57076320e-01\n",
      "  4.91967638e-01 3.45105456e-01]\n",
      " [5.15864429e-02 5.15864429e-02 0.00000000e+00 5.94320329e-02\n",
      "  3.88486992e-02 5.92567919e-02 2.43854018e-01 3.18221561e-01\n",
      "  2.96368269e-01 5.61524556e-02 5.61524556e-02 4.91862921e-02\n",
      "  3.14687892e-01 2.88800368e-01 8.45143827e-02 3.31693004e-01\n",
      "  1.32385131e-01 1.25363456e-01 1.21749510e-01 1.54455823e-01\n",
      "  2.34814220e-01 1.93433148e-01 4.17856897e-01 2.75814512e-01\n",
      "  4.65318755e-01 4.65318755e-01 3.51406424e-01 4.24695761e-01\n",
      "  4.59366260e-01 3.14146529e-01]\n",
      " [3.88837049e-02 3.88837049e-02 5.94320329e-02 0.00000000e+00\n",
      "  4.59814362e-02 2.82202589e-02 2.73696468e-01 3.47283243e-01\n",
      "  3.25924360e-01 3.60478379e-02 3.60478379e-02 6.22964259e-02\n",
      "  3.45965630e-01 3.21438211e-01 9.98030511e-02 3.63250560e-01\n",
      "  1.60903311e-01 1.50688179e-01 1.44433110e-01 1.81467564e-01\n",
      "  2.63014366e-01 2.20628185e-01 4.48994327e-01 3.05745753e-01\n",
      "  4.96259733e-01 4.96259733e-01 3.80629092e-01 4.55217228e-01\n",
      "  4.90021600e-01 3.43175542e-01]\n",
      " [5.17022054e-02 5.17022054e-02 3.88486992e-02 4.59814362e-02\n",
      "  0.00000000e+00 3.22911930e-02 2.32795838e-01 3.07003811e-01\n",
      "  2.85393413e-01 2.81932309e-02 2.81932309e-02 4.93313968e-02\n",
      "  3.04732126e-01 2.79888741e-01 6.89818338e-02 3.22251798e-01\n",
      "  1.27959638e-01 1.16360142e-01 1.20049536e-01 1.55059960e-01\n",
      "  2.29430897e-01 1.92149653e-01 4.12107117e-01 2.72915050e-01\n",
      "  4.59754388e-01 4.59754388e-01 3.45466310e-01 4.19169701e-01\n",
      "  4.53718695e-01 3.09005832e-01]\n",
      " [5.33979990e-02 5.33979990e-02 5.92567919e-02 2.82202589e-02\n",
      "  3.22911930e-02 0.00000000e+00 2.50047479e-01 3.23827164e-01\n",
      "  3.02503129e-01 1.10371435e-02 1.10371435e-02 5.78483638e-02\n",
      "  3.22276086e-01 2.97930569e-01 8.00843923e-02 3.39628589e-01\n",
      "  1.42813573e-01 1.31652655e-01 1.31951980e-01 1.66917093e-01\n",
      "  2.43397307e-01 2.04195888e-01 4.27600701e-01 2.86544861e-01\n",
      "  4.74972508e-01 4.74972508e-01 3.59804541e-01 4.34058557e-01\n",
      "  4.68767920e-01 3.22890094e-01]\n",
      " [2.78301211e-01 2.78301211e-01 2.43854018e-01 2.73696468e-01\n",
      "  2.32795838e-01 2.50047479e-01 0.00000000e+00 7.65680561e-02\n",
      "  5.48463877e-02 2.42615849e-01 2.42615849e-01 2.54646018e-01\n",
      "  8.40814688e-02 6.94039577e-02 2.07206476e-01 1.15466407e-01\n",
      "  1.90582052e-01 1.86048520e-01 2.32488043e-01 2.20544801e-01\n",
      "  1.83228401e-01 2.14056403e-01 2.53454343e-01 2.00109016e-01\n",
      "  2.92966369e-01 2.92966369e-01 2.18269445e-01 2.64326811e-01\n",
      "  2.89364368e-01 2.05912425e-01]\n",
      " [3.51710646e-01 3.51710646e-01 3.18221561e-01 3.47283243e-01\n",
      "  3.07003811e-01 3.23827164e-01 7.65680561e-02 0.00000000e+00\n",
      "  2.24509530e-02 3.16641068e-01 3.16641068e-01 3.29299996e-01\n",
      "  5.39526083e-02 7.14210951e-02 2.81006893e-01 9.10646588e-02\n",
      "  2.60758329e-01 2.56841405e-01 3.03500939e-01 2.87517329e-01\n",
      "  2.31303333e-01 2.74157215e-01 2.37802052e-01 2.36005121e-01\n",
      "  2.67213331e-01 2.67213331e-01 2.25055096e-01 2.49056161e-01\n",
      "  2.65385368e-01 2.27216775e-01]\n",
      " [3.30270081e-01 3.30270081e-01 2.96368269e-01 3.25924360e-01\n",
      "  2.85393413e-01 3.02503129e-01 5.48463877e-02 2.24509530e-02\n",
      "  0.00000000e+00 2.95194566e-01 2.95194566e-01 3.07377302e-01\n",
      "  5.28130431e-02 6.09266979e-02 2.59482298e-01 9.21162069e-02\n",
      "  2.40249551e-01 2.36063048e-01 2.82804365e-01 2.67871535e-01\n",
      "  2.16082172e-01 2.56161912e-01 2.40394751e-01 2.23953493e-01\n",
      "  2.73041852e-01 2.73041852e-01 2.20751089e-01 2.51562413e-01\n",
      "  2.70659655e-01 2.18908213e-01]\n",
      " [5.77252236e-02 5.77252236e-02 5.61524556e-02 3.60478379e-02\n",
      "  2.81932309e-02 1.10371435e-02 2.42615849e-01 3.16641068e-01\n",
      "  2.95194566e-01 0.00000000e+00 2.10734243e-08 5.19437264e-02\n",
      "  3.14039087e-01 2.89411679e-01 7.10125980e-02 3.31090939e-01\n",
      "  1.33715610e-01 1.22668139e-01 1.24783774e-01 1.59031957e-01\n",
      "  2.35048923e-01 1.96482829e-01 4.19331336e-01 2.78359453e-01\n",
      "  4.66801620e-01 4.66801620e-01 3.51651562e-01 4.25896004e-01\n",
      "  4.60638343e-01 3.14732556e-01]\n",
      " [5.77252236e-02 5.77252236e-02 5.61524556e-02 3.60478379e-02\n",
      "  2.81932309e-02 1.10371435e-02 2.42615849e-01 3.16641068e-01\n",
      "  2.95194566e-01 2.10734243e-08 0.00000000e+00 5.19437264e-02\n",
      "  3.14039087e-01 2.89411679e-01 7.10125980e-02 3.31090939e-01\n",
      "  1.33715610e-01 1.22668139e-01 1.24783774e-01 1.59031957e-01\n",
      "  2.35048923e-01 1.96482829e-01 4.19331336e-01 2.78359453e-01\n",
      "  4.66801620e-01 4.66801620e-01 3.51651562e-01 4.25896004e-01\n",
      "  4.60638343e-01 3.14732556e-01]\n",
      " [6.36135430e-02 6.36135430e-02 4.91862921e-02 6.22964259e-02\n",
      "  4.93313968e-02 5.78483638e-02 2.54646018e-01 3.29299996e-01\n",
      "  3.07377302e-01 5.19437264e-02 5.19437264e-02 0.00000000e+00\n",
      "  3.19864956e-01 2.93194300e-01 6.41132422e-02 3.33422862e-01\n",
      "  1.16176621e-01 1.09136717e-01 9.91442881e-02 1.37035559e-01\n",
      "  2.23662287e-01 1.78853015e-01 4.13640004e-01 2.67884155e-01\n",
      "  4.62097222e-01 4.62097222e-01 3.45223546e-01 4.20444725e-01\n",
      "  4.55931203e-01 3.06709402e-01]\n",
      " [3.49873635e-01 3.49873635e-01 3.14687892e-01 3.45965630e-01\n",
      "  3.04732126e-01 3.22276086e-01 8.40814688e-02 5.39526083e-02\n",
      "  5.28130431e-02 3.14039087e-01 3.14039087e-01 3.19864956e-01\n",
      "  0.00000000e+00 3.08636566e-02 2.68791251e-01 4.44592650e-02\n",
      "  2.40120435e-01 2.38043877e-01 2.84200278e-01 2.64417005e-01\n",
      "  2.00202012e-01 2.47723492e-01 2.03029893e-01 2.02778986e-01\n",
      "  2.36007676e-01 2.36007676e-01 1.89531109e-01 2.15491041e-01\n",
      "  2.33926100e-01 1.92283489e-01]\n",
      " [3.25137047e-01 3.25137047e-01 2.88800368e-01 3.21438211e-01\n",
      "  2.79888741e-01 2.97930569e-01 6.94039577e-02 7.14210951e-02\n",
      "  6.09266979e-02 2.89411679e-01 2.89411679e-01 2.93194300e-01\n",
      "  3.08636566e-02 0.00000000e+00 2.42115554e-01 5.22778984e-02\n",
      "  2.11119190e-01 2.10067359e-01 2.55992392e-01 2.35902483e-01\n",
      "  1.76019679e-01 2.21108926e-01 2.03844243e-01 1.82112554e-01\n",
      "  2.41671248e-01 2.41671248e-01 1.81025210e-01 2.16539061e-01\n",
      "  2.38923268e-01 1.77649431e-01]\n",
      " [1.06993303e-01 1.06993303e-01 8.45143827e-02 9.98030511e-02\n",
      "  6.89818338e-02 8.00843923e-02 2.07206476e-01 2.81006893e-01\n",
      "  2.59482298e-01 7.10125980e-02 7.10125980e-02 6.41132422e-02\n",
      "  2.68791251e-01 2.42115554e-01 0.00000000e+00 2.79300534e-01\n",
      "  7.10509011e-02 5.84391716e-02 7.43542013e-02 1.04767520e-01\n",
      "  1.75030425e-01 1.39952979e-01 3.61560523e-01 2.20235212e-01\n",
      "  4.10320242e-01 4.10320242e-01 2.94019851e-01 3.68884236e-01\n",
      "  4.04121854e-01 2.56815174e-01]\n",
      " [3.66835551e-01 3.66835551e-01 3.31693004e-01 3.63250560e-01\n",
      "  3.22251798e-01 3.39628589e-01 1.15466407e-01 9.10646588e-02\n",
      "  9.21162069e-02 3.31090939e-01 3.31090939e-01 3.33422862e-01\n",
      "  4.44592650e-02 5.22778984e-02 2.79300534e-01 0.00000000e+00\n",
      "  2.42851694e-01 2.42418741e-01 2.86558775e-01 2.62577055e-01\n",
      "  1.87247230e-01 2.40921510e-01 1.67235501e-01 1.83560282e-01\n",
      "  2.01228258e-01 2.01228258e-01 1.59655636e-01 1.80909858e-01\n",
      "  1.99192629e-01 1.67405414e-01]\n",
      " [1.63525592e-01 1.63525592e-01 1.32385131e-01 1.60903311e-01\n",
      "  1.27959638e-01 1.42813573e-01 1.90582052e-01 2.60758329e-01\n",
      "  2.40249551e-01 1.33715610e-01 1.33715610e-01 1.16176621e-01\n",
      "  2.40120435e-01 2.11119190e-01 7.10509011e-02 2.42851694e-01\n",
      "  0.00000000e+00 2.64855193e-02 5.86609245e-02 5.51769504e-02\n",
      "  1.18753025e-01 8.91235747e-02 3.07889224e-01 1.63487478e-01\n",
      "  3.57773739e-01 3.57773739e-01 2.41102518e-01 3.15815892e-01\n",
      "  3.51786016e-01 2.02660352e-01]\n",
      " [1.53420569e-01 1.53420569e-01 1.25363456e-01 1.50688179e-01\n",
      "  1.16360142e-01 1.31652655e-01 1.86048520e-01 2.56841405e-01\n",
      "  2.36063048e-01 1.22668139e-01 1.22668139e-01 1.09136717e-01\n",
      "  2.38043877e-01 2.10067359e-01 5.84391716e-02 2.42418741e-01\n",
      "  2.64855193e-02 0.00000000e+00 5.47774809e-02 6.41625475e-02\n",
      "  1.22013731e-01 9.31702778e-02 3.11007679e-01 1.68556436e-01\n",
      "  3.60701734e-01 3.60701734e-01 2.43279107e-01 3.18714973e-01\n",
      "  3.54518576e-01 2.05582431e-01]\n",
      " [1.44028342e-01 1.44028342e-01 1.21749510e-01 1.44433110e-01\n",
      "  1.20049536e-01 1.31951980e-01 2.32488043e-01 3.03500939e-01\n",
      "  2.82804365e-01 1.24783774e-01 1.24783774e-01 9.91442881e-02\n",
      "  2.84200278e-01 2.55992392e-01 7.43542013e-02 2.86558775e-01\n",
      "  5.86609245e-02 5.47774809e-02 0.00000000e+00 5.30528254e-02\n",
      "  1.42031327e-01 9.01384224e-02 3.37204627e-01 1.85857179e-01\n",
      "  3.87366481e-01 3.87366481e-01 2.67357592e-01 3.44042432e-01\n",
      "  3.80725402e-01 2.27235970e-01]\n",
      " [1.82684982e-01 1.82684982e-01 1.54455823e-01 1.81467564e-01\n",
      "  1.55059960e-01 1.66917093e-01 2.20544801e-01 2.87517329e-01\n",
      "  2.67871535e-01 1.59031957e-01 1.59031957e-01 1.37035559e-01\n",
      "  2.64417005e-01 2.35902483e-01 1.04767520e-01 2.62577055e-01\n",
      "  5.51769504e-02 6.41625475e-02 5.30528254e-02 0.00000000e+00\n",
      "  1.02620836e-01 5.19018813e-02 2.99084891e-01 1.43454348e-01\n",
      "  3.48608659e-01 3.48608659e-01 2.28336264e-01 3.05013038e-01\n",
      "  3.42092943e-01 1.86926687e-01]\n",
      " [2.65005776e-01 2.65005776e-01 2.34814220e-01 2.63014366e-01\n",
      "  2.29430897e-01 2.43397307e-01 1.83228401e-01 2.31303333e-01\n",
      "  2.16082172e-01 2.35048923e-01 2.35048923e-01 2.23662287e-01\n",
      "  2.00202012e-01 1.76019679e-01 1.75030425e-01 1.87247230e-01\n",
      "  1.18753025e-01 1.22013731e-01 1.42031327e-01 1.02620836e-01\n",
      "  0.00000000e+00 6.68185449e-02 1.99379048e-01 5.43126878e-02\n",
      "  2.49741474e-01 2.49741474e-01 1.28793011e-01 2.05966736e-01\n",
      "  2.43174797e-01 8.93449397e-02]\n",
      " [2.21213755e-01 2.21213755e-01 1.93433148e-01 2.20628185e-01\n",
      "  1.92149653e-01 2.04195888e-01 2.14056403e-01 2.74157215e-01\n",
      "  2.56161912e-01 1.96482829e-01 1.96482829e-01 1.78853015e-01\n",
      "  2.47723492e-01 2.21108926e-01 1.39952979e-01 2.40921510e-01\n",
      "  8.91235747e-02 9.31702778e-02 9.01384224e-02 5.19018813e-02\n",
      "  6.68185449e-02 0.00000000e+00 2.58793061e-01 1.02355759e-01\n",
      "  3.08254766e-01 3.08254766e-01 1.86722428e-01 2.63793712e-01\n",
      "  3.01277401e-01 1.45147285e-01]\n",
      " [4.50767453e-01 4.50767453e-01 4.17856897e-01 4.48994327e-01\n",
      "  4.12107117e-01 4.27600701e-01 2.53454343e-01 2.37802052e-01\n",
      "  2.40394751e-01 4.19331336e-01 4.19331336e-01 4.13640004e-01\n",
      "  2.03029893e-01 2.03844243e-01 3.61560523e-01 1.67235501e-01\n",
      "  3.07889224e-01 3.11007679e-01 3.37204627e-01 2.99084891e-01\n",
      "  1.99379048e-01 2.58793061e-01 0.00000000e+00 1.62143875e-01\n",
      "  5.51725235e-02 5.51725235e-02 7.97879194e-02 2.78022384e-02\n",
      "  5.07930362e-02 1.20239224e-01]\n",
      " [3.07780632e-01 3.07780632e-01 2.75814512e-01 3.05745753e-01\n",
      "  2.72915050e-01 2.86544861e-01 2.00109016e-01 2.36005121e-01\n",
      "  2.23953493e-01 2.78359453e-01 2.78359453e-01 2.67884155e-01\n",
      "  2.02778986e-01 1.82112554e-01 2.20235212e-01 1.83560282e-01\n",
      "  1.63487478e-01 1.68556436e-01 1.85857179e-01 1.43454348e-01\n",
      "  5.43126878e-02 1.02355759e-01 1.62143875e-01 0.00000000e+00\n",
      "  2.09593723e-01 2.09593723e-01 8.95196557e-02 1.65138222e-01\n",
      "  2.02661359e-01 4.85527584e-02]\n",
      " [4.98166068e-01 4.98166068e-01 4.65318755e-01 4.96259733e-01\n",
      "  4.59754388e-01 4.74972508e-01 2.92966369e-01 2.67213331e-01\n",
      "  2.73041852e-01 4.66801620e-01 4.66801620e-01 4.62097222e-01\n",
      "  2.36007676e-01 2.41671248e-01 4.10320242e-01 2.01228258e-01\n",
      "  3.57773739e-01 3.60701734e-01 3.87366481e-01 3.48608659e-01\n",
      "  2.49741474e-01 3.08254766e-01 5.51725235e-02 2.09593723e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.24418241e-01 4.59819939e-02\n",
      "  1.07944539e-02 1.66256831e-01]\n",
      " [4.98166068e-01 4.98166068e-01 4.65318755e-01 4.96259733e-01\n",
      "  4.59754388e-01 4.74972508e-01 2.92966369e-01 2.67213331e-01\n",
      "  2.73041852e-01 4.66801620e-01 4.66801620e-01 4.62097222e-01\n",
      "  2.36007676e-01 2.41671248e-01 4.10320242e-01 2.01228258e-01\n",
      "  3.57773739e-01 3.60701734e-01 3.87366481e-01 3.48608659e-01\n",
      "  2.49741474e-01 3.08254766e-01 5.51725235e-02 2.09593723e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.24418241e-01 4.59819939e-02\n",
      "  1.07944539e-02 1.66256831e-01]\n",
      " [3.82586229e-01 3.82586229e-01 3.51406424e-01 3.80629092e-01\n",
      "  3.45466310e-01 3.59804541e-01 2.18269445e-01 2.25055096e-01\n",
      "  2.20751089e-01 3.51651562e-01 3.51651562e-01 3.45223546e-01\n",
      "  1.89531109e-01 1.81025210e-01 2.94019851e-01 1.59655636e-01\n",
      "  2.41102518e-01 2.43279107e-01 2.67357592e-01 2.28336264e-01\n",
      "  1.28793011e-01 1.86722428e-01 7.97879194e-02 8.95196557e-02\n",
      "  1.24418241e-01 1.24418241e-01 0.00000000e+00 7.93535200e-02\n",
      "  1.16961891e-01 4.30044569e-02]\n",
      " [4.57076320e-01 4.57076320e-01 4.24695761e-01 4.55217228e-01\n",
      "  4.19169701e-01 4.34058557e-01 2.64326811e-01 2.49056161e-01\n",
      "  2.51562413e-01 4.25896004e-01 4.25896004e-01 4.20444725e-01\n",
      "  2.15491041e-01 2.16539061e-01 3.68884236e-01 1.80909858e-01\n",
      "  3.15815892e-01 3.18714973e-01 3.44042432e-01 3.05013038e-01\n",
      "  2.05966736e-01 2.63793712e-01 2.78022384e-02 1.65138222e-01\n",
      "  4.59819939e-02 4.59819939e-02 7.93535200e-02 0.00000000e+00\n",
      "  3.81194022e-02 1.21057233e-01]\n",
      " [4.91967638e-01 4.91967638e-01 4.59366260e-01 4.90021600e-01\n",
      "  4.53718695e-01 4.68767920e-01 2.89364368e-01 2.65385368e-01\n",
      "  2.70659655e-01 4.60638343e-01 4.60638343e-01 4.55931203e-01\n",
      "  2.33926100e-01 2.38923268e-01 4.04121854e-01 1.99192629e-01\n",
      "  3.51786016e-01 3.54518576e-01 3.80725402e-01 3.42092943e-01\n",
      "  2.43174797e-01 3.01277401e-01 5.07930362e-02 2.02661359e-01\n",
      "  1.07944539e-02 1.07944539e-02 1.16961891e-01 3.81194022e-02\n",
      "  0.00000000e+00 1.58861659e-01]\n",
      " [3.45105456e-01 3.45105456e-01 3.14146529e-01 3.43175542e-01\n",
      "  3.09005832e-01 3.22890094e-01 2.05912425e-01 2.27216775e-01\n",
      "  2.18908213e-01 3.14732556e-01 3.14732556e-01 3.06709402e-01\n",
      "  1.92283489e-01 1.77649431e-01 2.56815174e-01 1.67405414e-01\n",
      "  2.02660352e-01 2.05582431e-01 2.27235970e-01 1.86926687e-01\n",
      "  8.93449397e-02 1.45147285e-01 1.20239224e-01 4.85527584e-02\n",
      "  1.66256831e-01 1.66256831e-01 4.30044569e-02 1.21057233e-01\n",
      "  1.58861659e-01 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PPI_pd = pairwise_distances(PPI_sm, metric='euclidean')\n",
    "print(PPI_pd)\n",
    "# SHOCK_pd = pairwise_distances(SHOCK_sm, metric='euclidean')\n",
    "plt.imshow(PPI_pd, zorder=2, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 - 0.9333333333333332 - 1.0 - 0.13333333333333336\n"
     ]
    }
   ],
   "source": [
    "strat_k_fold = StratifiedKFold(n_splits = 10, shuffle = True) \n",
    "clf = svm.SVC(kernel=\"linear\", C = 1.0)\n",
    "scores_ln = cross_val_score(clf, PPI_pd, PPI_labels[20:50], cv = strat_k_fold)\n",
    "print(str(np.min(scores_ln)) +\" - \"+str(np.mean(scores_ln))+ \" - \" + str(np.max(scores_ln)) + \" - \"+ str(np.std(scores_ln)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
